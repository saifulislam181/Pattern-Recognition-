# -*- coding: utf-8 -*-
"""naive bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ih_Yeb9MywTaosQ07iQeRoo0ZSzV2_le

CSI 416 (A): Pattern Recognition Lab
                              Assignment 1
                            Md.Saiful Islam
                             ID 011181292

# Import Dic
"""

import numpy as nm  
import matplotlib.pyplot as mtp  
import pandas as pd 
from sklearn.preprocessing import StandardScaler 
from sklearn.preprocessing import LabelEncoder
levelencoder=LabelEncoder()
from sklearn.preprocessing import OneHotEncoder

"""# Importing the dataset  """

dataset = pd.read_csv('dataset.csv')  
x = dataset.loc[:, dataset.columns != "Class"]  
dataset.head()
y = dataset.iloc[:, ].Class  
dataset.head()

"""# Counts"""

from collections import Counter
Counter(dataset['Class'])

dataset['Class'].value_counts()

x = dataset.loc[:, dataset.columns != "Class"]
y = dataset["Class"]

print(x.shape)
print(y.shape)

"""# Splitting the dataset into the Training set and Test set  """

from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, stratify=y)  
print(x_train.shape)
print(y_test.shape)
print(x_train)

"""# LabelEncoding"""

New_Data=dataset[["top-left-square","top-middle-square","top-right-square","middle-left-square",
                  "middle-middle-square","middle-right-square","bottom-left-square","bottom-middle-square","bottom-right-square","Class"]]


le=LabelEncoder()

#Check Data
New_Data
#working....

le.fit_transform(New_Data["top-left-square"])
le.fit_transform(New_Data["top-middle-square"])
le.fit_transform(New_Data["top-right-square"])

le.fit_transform(New_Data["middle-left-square"])
le.fit_transform(New_Data["middle-middle-square"])
le.fit_transform(New_Data["middle-right-square"])

le.fit_transform(New_Data["bottom-left-square"])
le.fit_transform(New_Data["bottom-middle-square"])
le.fit_transform(New_Data["bottom-right-square"])

le.fit_transform(New_Data["Class"])

"""# Create New Data Columns"""

New_Data["top-left-square2"]=le.fit_transform(New_Data["top-left-square"])
New_Data["top-middle-square2"]=le.fit_transform(New_Data["top-middle-square"])
New_Data["top-right-square2"]=le.fit_transform(New_Data["top-right-square"])

New_Data["middle-left-square2"]=le.fit_transform(New_Data["middle-left-square"])
New_Data["middle-middle-square2"]=le.fit_transform(New_Data["middle-middle-square"])
New_Data["middle-right-square2"]=le.fit_transform(New_Data["middle-right-square"])

New_Data["bottom-left-square2"]=le.fit_transform(New_Data["bottom-left-square"])
New_Data["bottom-middle-square2"]=le.fit_transform(New_Data["bottom-middle-square"])
New_Data["bottom-right-square2"]=le.fit_transform(New_Data["bottom-right-square"])

New_Data["New_Class"]=le.fit_transform(New_Data["Class"])



New_Data

"""# Drop Old Data Columns"""

dataset=New_Data.drop(columns=['top-left-square','top-middle-square','top-right-square','middle-left-square','middle-middle-square',
                       'middle-right-square','bottom-left-square','bottom-middle-square','bottom-right-square','Class'])
dataset


#working

"""# Again Check All of Data and Data Shape ,Total data,split data"""

x = dataset.loc[:, dataset.columns != "New_Class"]
y = dataset["New_Class"]

print(x.shape)
print(y.shape)


#Here Class new name is "New_Class"

from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10 ,stratify=y  )
print(x_train.shape)
print(y_test.shape)
x_train

#New Data set perfect working after encoding

"""# Counts After Encoding"""

from collections import Counter
Counter(New_Data['New_Class'])

New_Data['New_Class'].value_counts()

"""# Using Gaussian Method"""

from sklearn.naive_bayes import GaussianNB  
classifier = GaussianNB()

classifier.fit(x_train, y_train)

"""# Fitting Naive Bayes to the Training set  """

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, zero_one_loss
from sklearn.metrics import classification_report

from sklearn.naive_bayes import GaussianNB  
classifier = GaussianNB()  
classifier.fit(x_train, y_train)

"""# Predicting the Test set results"""

y_pred= classifier.predict(x_test)

print("Accuracy Score : ",accuracy_score(y_test,y_pred)*100,"%")
print("Precision Score : ",precision_score(y_test,y_pred)*100,"%")
print("Recall Score : ",recall_score(y_test,y_pred)*100,"%")
print("F1 Score : ",f1_score(y_test,y_pred)*100,"%")

from sklearn import metrics
print("Gaussian Naive Bayes model accuracy(in %):", metrics.accuracy_score(y_test, y_pred)*100,"%")

"""# Using Multinomial Method For Accueacy score"""

from sklearn.naive_bayes import MultinomialNB
classifier_m = MultinomialNB()
classifier_m.fit(x_train, y_train)
acc=classifier_m.score(x_test, y_test)
print("Accuracy Score : ",acc*100,"%")

"""# Using Bernoulli Method For Accueracy score

"""

from sklearn.naive_bayes import BernoulliNB
classifier_b = BernoulliNB()
classifier_b.fit(x_train, y_train)
 
acc2=classifier_b.score(x_test, y_test)
print("Accuracy Score : ",acc2*100,"%")

print(classification_report(y_test,y_pred))

"""# Check Some of Data For Testing(Report)"""

x_test[:10]

y_test[:10]

classifier.predict(x_test[:15])

"""## Without Stratification"""

from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10  )
print(x_train.shape)
print(y_test.shape)
x_train

from sklearn.naive_bayes import GaussianNB  
classifier = GaussianNB()
classifier.fit(x_train, y_train)

from collections import Counter
Counter(New_Data['New_Class'])

y_pred2= classifier.predict(x_test)

print("Accuracy Score : ",accuracy_score(y_test,y_pred2)*100,"%")
print("Precision Score : ",precision_score(y_test,y_pred2)*100,"%")
print("Recall Score : ",recall_score(y_test,y_pred2)*100,"%")
print("F1 Score : ",f1_score(y_test,y_pred2)*100,"%")

"""# Using Multinomial Method For Accueacy score"""

from sklearn.naive_bayes import MultinomialNB
classifier_m = MultinomialNB()
classifier_m.fit(x_train, y_train)
acc=classifier_m.score(x_test, y_test)
print("Accuracy Score : ",acc*100,"%")

"""# Using Bernoulli Method For Accueracy score"""

from sklearn.naive_bayes import BernoulliNB
classifier_b = BernoulliNB()
classifier_b.fit(x_train, y_train)
 
acc2=classifier_b.score(x_test, y_test)
print("Accuracy Score : ",acc2*100,"%")

print(classification_report(y_test,y_pred2))

"""# Mannual Gousian Method"""

import torch
import numpy as np
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, zero_one_loss
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

class NaiveBayes:
    def __init__(self, X, y):
     
        self.total_samples, self.feature_count = X.shape[0], X.shape[1]
        self.mu = {}
        self.sigma = {}
        self.prior_probability_X = {}
        self.e = 1e-4
        self.n_classes = len(y.unique())
    def find_mu_and_sigma(self, X, y):

        for cls in range(self.n_classes):
            X_class = X[y==cls]
            self.mu[cls] = torch.mean(X_class, dim=0)
            self.sigma[cls] = torch.var(X_class, dim=0)
            self.prior_probability_X[cls] = X_class.shape[0] / X.shape[0]
    def fit_function(self, X, mu, sigma):
        
        constant = - self.feature_count / 2 * torch.log(2 * torch.tensor(np.pi)) - 0.5 * torch.sum(torch.log(sigma+self.e))
        probability = 0.5 * torch.sum(torch.pow(X-mu, 2) / (sigma + self.e), dim=1)
        return constant - probability
    def predict_function(self, X):
      
        probabilities = torch.zeros((X.shape[0], self.n_classes))
        for cls in range(self.n_classes):
            class_probability = self.fit_function(X, self.mu[cls], self.sigma[cls])
            probabilities[:, cls] = class_probability + torch.log(torch.scalar_tensor(self.prior_probability_X[cls]))


        return torch.argmax(probabilities, dim=1)

if __name__ == '__main__':
    dataset = pd.read_csv('dataset.csv')  
    x = dataset.loc[:, dataset.columns != "Class"]  
    dataset.head()
    y = dataset.iloc[:, ].Class  
    dataset.head()
    x = torch.tensor(dataset.Class)
    y = torch.tensor(dataset.target)
    torch.manual_seed(0)
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,stratify=y)
    GNB = NaiveBayes(x_train, y_train)
    GNB.find_mu_and_sigma(x_train, y_train)
    y_pred = GNB.predict_function(x_test)

print('Accuracy Score: ',{accuracy_score(y_test, y_pred)})
print("Precision Score : ",precision_score(y_test, y_pred, pos_label='positive', average='micro')*100)
print("Recall Score : ",recall_score(y_test, y_pred,  pos_label='positive',average='micro')*100)
print("F1 : ",f1_score(y_test, y_pred,  pos_label='positive',average='micro')*100)

if __name__ == '__main__':
    dataset = pd.read_csv('dataset.csv')  
    x = dataset.loc[:, dataset.columns != "Class"]  
    dataset.head()
    y = dataset.iloc[:, ].Class  
    dataset.head()
    x = torch.tensor(dataset.Class)
    y = torch.tensor(dataset.target)
    torch.manual_seed(0)
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)
    GNB = NaiveBayes(x_train, y_train)
    GNB.find_mu_and_sigma(x_train, y_train)
    y_pred = GNB.predict_function(x_test)

print('Accuracy Score: ',{accuracy_score(y_test, y_pred)})
print("Precision Score : ",precision_score(y_test, y_pred, pos_label='positive', average='micro')*100)
print("Recall Score : ",recall_score(y_test, y_pred,  pos_label='positive',average='micro')*100)
print("F1 : ",f1_score(y_test, y_pred,  pos_label='positive',average='micro')*100)